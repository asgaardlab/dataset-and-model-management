call_root_type,method_name,method_call,line_no,call_root,call_root_line_no,qualifying_name,call_root_package,relative_file_path,repository_name,file_path
import,load,"X = np.load(""X.npy"")",8,import numpy as np,1.0,numpy.load,numpy,finance/transformer/evaluate.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\finance\transformer\evaluate.py
import,load,"Y = np.load(""Y.npy"")",9,import numpy as np,1.0,numpy.load,numpy,finance/transformer/evaluate.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\finance\transformer\evaluate.py
assignment_import,load_weights,model.load_weights(checkpoint_filepath),16,model = get_model(),15.0,train.get_model.load_weights,train,finance/transformer/evaluate.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\finance\transformer\evaluate.py
assignment_import,fit,scaler.fit(data),35,scaler = preprocessing.StandardScaler(),34.0,sklearn.preprocessing.fit,sklearn,finance/transformer/gen_data.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\finance\transformer\gen_data.py
assignment_import,load_weights,model.load_weights(checkpoint_filepath),12,model = get_model(),11.0,train.get_model.load_weights,train,finance/transformer/predict.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\finance\transformer\predict.py
import,load,"X = np.load(""X.npy"")",79,import numpy as np,7.0,numpy.load,numpy,finance/transformer/train.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\finance\transformer\train.py
import,load,"Y = np.load(""Y.npy"")",80,import numpy as np,7.0,numpy.load,numpy,finance/transformer/train.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\finance\transformer\train.py
assignment_unknown,fit,model.fit(,115,model = get_model(),95.0,get_model.fit,get_model,finance/transformer/train.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\finance\transformer\train.py
import,load,"X = np.load(""X.npy"")",8,import numpy as np,1.0,numpy.load,numpy,finance/transformer-volatility/evaluate.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\finance\transformer-volatility\evaluate.py
import,load,"Y = np.load(""Y.npy"")",9,import numpy as np,1.0,numpy.load,numpy,finance/transformer-volatility/evaluate.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\finance\transformer-volatility\evaluate.py
assignment_import,load_weights,model.load_weights(checkpoint_filepath),20,model = get_model(),19.0,train.get_model.load_weights,train,finance/transformer-volatility/evaluate.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\finance\transformer-volatility\evaluate.py
assignment_import,fit,scaler.fit(data),33,scaler = preprocessing.StandardScaler(),32.0,sklearn.preprocessing.fit,sklearn,finance/transformer-volatility/gen_data.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\finance\transformer-volatility\gen_data.py
assignment_import,load_weights,model.load_weights(checkpoint_filepath),12,model = get_model(),11.0,train.get_model.load_weights,train,finance/transformer-volatility/predict.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\finance\transformer-volatility\predict.py
import,load,"X = np.load(""X.npy"")",80,import numpy as np,7.0,numpy.load,numpy,finance/transformer-volatility/train.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\finance\transformer-volatility\train.py
import,load,"Y = np.load(""Y.npy"")",81,import numpy as np,7.0,numpy.load,numpy,finance/transformer-volatility/train.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\finance\transformer-volatility\train.py
assignment_unknown,fit,model.fit(,118,model = get_model(),97.0,get_model.fit,get_model,finance/transformer-volatility/train.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\finance\transformer-volatility\train.py
,load_weights,vqvae_trainer.vqvae.load_weights(vqvae_weights_file),426,,,vqvae_trainer.vqvae.load_weights,vqvae_trainer,stable-diffusion/ct/diffusion_image.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\ct\diffusion_image.py
assignment_import,load_weights,model.load_weights(checkpoint_path),493,"model = DiffusionModel(image_size, widths, block_depth)",468.0,tensorflow.keras.load_weights,tensorflow,stable-diffusion/ct/diffusion_image.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\ct\diffusion_image.py
assignment_import,fit,model.fit(,496,"model = DiffusionModel(image_size, widths, block_depth)",468.0,tensorflow.keras.fit,tensorflow,stable-diffusion/ct/diffusion_image.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\ct\diffusion_image.py
assignment_import,load_weights,model.load_weights(checkpoint_path),513,"model = DiffusionModel(image_size, widths, block_depth)",468.0,tensorflow.keras.load_weights,tensorflow,stable-diffusion/ct/diffusion_image.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\ct\diffusion_image.py
assignment_import,load_weights,model.load_weights(checkpoint_path),459,"model = DiffusionModel(image_size, widths, block_depth)",434.0,tensorflow.keras.load_weights,tensorflow,stable-diffusion/ct/diffusion_mask.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\ct\diffusion_mask.py
assignment_import,fit,model.fit(,462,"model = DiffusionModel(image_size, widths, block_depth)",434.0,tensorflow.keras.fit,tensorflow,stable-diffusion/ct/diffusion_mask.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\ct\diffusion_mask.py
assignment_import,load_weights,model.load_weights(checkpoint_path),479,"model = DiffusionModel(image_size, widths, block_depth)",434.0,tensorflow.keras.load_weights,tensorflow,stable-diffusion/ct/diffusion_mask.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\ct\diffusion_mask.py
assignment_import,fit,vqvae_trainer.fit(,259,"vqvae_trainer = VQVAETrainer(data_variance, LATENT_DIM, NUM_EMBEDDINGS)",253.0,tensorflow.keras.fit,tensorflow,stable-diffusion/ct/vqvae.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\ct\vqvae.py
,load_weights,vqvae_trainer.vqvae.load_weights(vqvae_weights_file),267,,,vqvae_trainer.vqvae.load_weights,vqvae_trainer,stable-diffusion/ct/vqvae.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\ct\vqvae.py
assignment_import,fit,pixel_cnn.fit(,449,"pixel_cnn = keras.Model(pixelcnn_inputs, out, name=""pixel_cnn"")",411.0,tensorflow.keras.fit,tensorflow,stable-diffusion/ct/vqvae.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\ct\vqvae.py
assignment_import,load_weights,pixel_cnn.load_weights(pixel_cnn_weight_file),457,"pixel_cnn = keras.Model(pixelcnn_inputs, out, name=""pixel_cnn"")",411.0,tensorflow.keras.load_weights,tensorflow,stable-diffusion/ct/vqvae.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\ct\vqvae.py
assignment_import,fit,"vqvae_trainer.fit(x_train_scaled, epochs=4, batch_size=128)",279,"vqvae_trainer = VQVAETrainer(data_variance, latent_dim=16, num_embeddings=128)",277.0,tensorflow.keras.fit,tensorflow,stable-diffusion/ct/vq_vae.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\ct\vq_vae.py
assignment_import,fit,pixel_cnn.fit(,513,"pixel_cnn = keras.Model(pixelcnn_inputs, out, name=""pixel_cnn"")",474.0,tensorflow.keras.fit,tensorflow,stable-diffusion/ct/vq_vae.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\ct\vq_vae.py
assignment_import,fit,model.fit(,457,"model = DiffusionModel(image_size, widths, block_depth)",430.0,tensorflow.keras.fit,tensorflow,stable-diffusion/ddim/celeba.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\ddim\celeba.py
assignment_import,load_weights,model.load_weights(checkpoint_path),474,"model = DiffusionModel(image_size, widths, block_depth)",430.0,tensorflow.keras.load_weights,tensorflow,stable-diffusion/ddim/celeba.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\ddim\celeba.py
import,load,"tfds.load(dataset_name, split=split, shuffle_files=True)",86,import tensorflow_datasets as tfds,12.0,tensorflow_datasets.load,tensorflow_datasets,stable-diffusion/ddim/cityscapes.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\ddim\cityscapes.py
assignment_import,fit,model.fit(,482,"model = DiffusionModel(image_size, widths, block_depth)",456.0,tensorflow.keras.fit,tensorflow,stable-diffusion/ddim/cityscapes.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\ddim\cityscapes.py
assignment_import,load_weights,model.load_weights(checkpoint_path),499,"model = DiffusionModel(image_size, widths, block_depth)",456.0,tensorflow.keras.load_weights,tensorflow,stable-diffusion/ddim/cityscapes.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\ddim\cityscapes.py
import,load,"tfds.load(dataset_name, split=split, shuffle_files=True)",85,import tensorflow_datasets as tfds,11.0,tensorflow_datasets.load,tensorflow_datasets,stable-diffusion/ddim/ddim.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\ddim\ddim.py
assignment_import,fit,model.fit(,634,"model = DiffusionModel(image_size, widths, block_depth)",607.0,tensorflow.keras.fit,tensorflow,stable-diffusion/ddim/ddim.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\ddim\ddim.py
assignment_import,load_weights,model.load_weights(checkpoint_path),651,"model = DiffusionModel(image_size, widths, block_depth)",607.0,tensorflow.keras.load_weights,tensorflow,stable-diffusion/ddim/ddim.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\ddim\ddim.py
assignment_import,fit,model.fit(,480,"model = DiffusionModel(image_size, widths, block_depth)",453.0,tensorflow.keras.fit,tensorflow,stable-diffusion/ddim/deeplesion.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\ddim\deeplesion.py
assignment_import,load_weights,model.load_weights(checkpoint_path),497,"model = DiffusionModel(image_size, widths, block_depth)",453.0,tensorflow.keras.load_weights,tensorflow,stable-diffusion/ddim/deeplesion.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\ddim\deeplesion.py
assignment_import,load_weights,model.load_weights(checkpoint_path),30,"model = DiffusionModel(image_size, widths, block_depth)",21.0,totalseg.DiffusionModel.load_weights,totalseg,stable-diffusion/semantic-synthesis/inference.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\semantic-synthesis\inference.py
,load_weights,model.network.load_weights(f'{TMP_DIR}/network_{epoch}.h5'),31,,,model.network.load_weights,model,stable-diffusion/semantic-synthesis/inference.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\semantic-synthesis\inference.py
,load_weights,model.ema_network.load_weights(f'{TMP_DIR}/ema_network_{epoch}.h5'),32,,,model.ema_network.load_weights,model,stable-diffusion/semantic-synthesis/inference.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\semantic-synthesis\inference.py
assignment_import,load_weights,model.load_weights(checkpoint_path),632,"model = DiffusionModel(image_size, widths, block_depth)",607.0,tensorflow.keras.load_weights,tensorflow,stable-diffusion/semantic-synthesis/totalseg.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\semantic-synthesis\totalseg.py
assignment_import,fit,model.fit(,635,"model = DiffusionModel(image_size, widths, block_depth)",607.0,tensorflow.keras.fit,tensorflow,stable-diffusion/semantic-synthesis/totalseg.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\semantic-synthesis\totalseg.py
assignment_import,load_weights,model.load_weights(checkpoint_path),652,"model = DiffusionModel(image_size, widths, block_depth)",607.0,tensorflow.keras.load_weights,tensorflow,stable-diffusion/semantic-synthesis/totalseg.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\semantic-synthesis\totalseg.py
import,load,"tfds.load(dataset_name, split=split, shuffle_files=True)",86,import tensorflow_datasets as tfds,12.0,tensorflow_datasets.load,tensorflow_datasets,stable-diffusion/semantic-synthesis/cityscapes/ddim.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\semantic-synthesis\cityscapes\ddim.py
assignment_import,fit,model.fit(,492,"model = DiffusionModel(image_size, widths, block_depth)",466.0,tensorflow.keras.fit,tensorflow,stable-diffusion/semantic-synthesis/cityscapes/ddim.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\semantic-synthesis\cityscapes\ddim.py
assignment_import,load_weights,model.load_weights(checkpoint_path),509,"model = DiffusionModel(image_size, widths, block_depth)",466.0,tensorflow.keras.load_weights,tensorflow,stable-diffusion/semantic-synthesis/cityscapes/ddim.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\semantic-synthesis\cityscapes\ddim.py
assignment_import,load_weights,model.load_weights(checkpoint_path),630,"model = DiffusionModel(image_size, widths, block_depth)",605.0,tensorflow.keras.load_weights,tensorflow,stable-diffusion/semantic-synthesis/highres/totalseg.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\semantic-synthesis\highres\totalseg.py
assignment_import,fit,model.fit(,633,"model = DiffusionModel(image_size, widths, block_depth)",605.0,tensorflow.keras.fit,tensorflow,stable-diffusion/semantic-synthesis/highres/totalseg.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\semantic-synthesis\highres\totalseg.py
assignment_import,load_weights,model.load_weights(checkpoint_path),650,"model = DiffusionModel(image_size, widths, block_depth)",605.0,tensorflow.keras.load_weights,tensorflow,stable-diffusion/semantic-synthesis/highres/totalseg.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\semantic-synthesis\highres\totalseg.py
