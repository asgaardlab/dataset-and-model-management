call_name,line_no,class_instantiation,instantiation_line_no,relative_file_path,repository_name,file_path
"self.encoder(real_images, training=False)",100,"self.encoder = keras.Sequential([keras.Input(shape=(image_size, image_size, 3)), layers.Rescaling(255.0), layers.Resizing(height=kid_image_size, width=kid_image_size), layers.Lambda(keras.applications.inception_v3.preprocess_input), keras.applications.InceptionV3(include_top=False, input_shape=(kid_image_size, kid_image_size, 3), weights='imagenet'), layers.GlobalAveragePooling2D()], name='inception_encoder')",76,stable-diffusion/ct/diffusion_image.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\ct\diffusion_image.py
"self.encoder(generated_images, training=False)",101,"self.encoder = keras.Sequential([keras.Input(shape=(image_size, image_size, 3)), layers.Rescaling(255.0), layers.Resizing(height=kid_image_size, width=kid_image_size), layers.Lambda(keras.applications.inception_v3.preprocess_input), keras.applications.InceptionV3(include_top=False, input_shape=(kid_image_size, kid_image_size, 3), weights='imagenet'), layers.GlobalAveragePooling2D()], name='inception_encoder')",76,stable-diffusion/ct/diffusion_image.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\ct\diffusion_image.py
"self.encoder(real_images, training=False)",100,"self.encoder = keras.Sequential([keras.Input(shape=(image_size, image_size, 3)), layers.Rescaling(255.0), layers.Resizing(height=kid_image_size, width=kid_image_size), layers.Lambda(keras.applications.inception_v3.preprocess_input), keras.applications.InceptionV3(include_top=False, input_shape=(kid_image_size, kid_image_size, 3), weights='imagenet'), layers.GlobalAveragePooling2D()], name='inception_encoder')",76,stable-diffusion/ct/diffusion_mask.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\ct\diffusion_mask.py
"self.encoder(generated_images, training=False)",101,"self.encoder = keras.Sequential([keras.Input(shape=(image_size, image_size, 3)), layers.Rescaling(255.0), layers.Resizing(height=kid_image_size, width=kid_image_size), layers.Lambda(keras.applications.inception_v3.preprocess_input), keras.applications.InceptionV3(include_top=False, input_shape=(kid_image_size, kid_image_size, 3), weights='imagenet'), layers.GlobalAveragePooling2D()], name='inception_encoder')",76,stable-diffusion/ct/diffusion_mask.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\ct\diffusion_mask.py
"pixel_cnn(inputs, training=False)",534,"pixel_cnn = keras.Model(pixelcnn_inputs, out, name='pixel_cnn')",474,stable-diffusion/ct/vq_vae.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\ct\vq_vae.py
"pixel_cnn(inputs, training=False)",461,"pixel_cnn = keras.Model(pixelcnn_inputs, out, name='pixel_cnn')",411,stable-diffusion/ct/vqvae.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\ct\vqvae.py
"self.encoder(real_images, training=False)",129,"self.encoder = keras.Sequential([keras.Input(shape=(image_size, image_size, 3)), layers.Rescaling(255.0), layers.Resizing(height=kid_image_size, width=kid_image_size), layers.Lambda(keras.applications.inception_v3.preprocess_input), keras.applications.InceptionV3(include_top=False, input_shape=(kid_image_size, kid_image_size, 3), weights='imagenet'), layers.GlobalAveragePooling2D()], name='inception_encoder')",108,stable-diffusion/ddim/celeba.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\ddim\celeba.py
"self.encoder(generated_images, training=False)",130,"self.encoder = keras.Sequential([keras.Input(shape=(image_size, image_size, 3)), layers.Rescaling(255.0), layers.Resizing(height=kid_image_size, width=kid_image_size), layers.Lambda(keras.applications.inception_v3.preprocess_input), keras.applications.InceptionV3(include_top=False, input_shape=(kid_image_size, kid_image_size, 3), weights='imagenet'), layers.GlobalAveragePooling2D()], name='inception_encoder')",108,stable-diffusion/ddim/celeba.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\ddim\celeba.py
"self.encoder(real_images, training=False)",154,"self.encoder = keras.Sequential([keras.Input(shape=(image_size, image_size, 3)), layers.Rescaling(255.0), layers.Resizing(height=kid_image_size, width=kid_image_size), layers.Lambda(keras.applications.inception_v3.preprocess_input), keras.applications.InceptionV3(include_top=False, input_shape=(kid_image_size, kid_image_size, 3), weights='imagenet'), layers.GlobalAveragePooling2D()], name='inception_encoder')",133,stable-diffusion/ddim/cityscapes.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\ddim\cityscapes.py
"self.encoder(generated_images, training=False)",155,"self.encoder = keras.Sequential([keras.Input(shape=(image_size, image_size, 3)), layers.Rescaling(255.0), layers.Resizing(height=kid_image_size, width=kid_image_size), layers.Lambda(keras.applications.inception_v3.preprocess_input), keras.applications.InceptionV3(include_top=False, input_shape=(kid_image_size, kid_image_size, 3), weights='imagenet'), layers.GlobalAveragePooling2D()], name='inception_encoder')",133,stable-diffusion/ddim/cityscapes.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\ddim\cityscapes.py
"self.encoder(real_images, training=False)",173,"self.encoder = keras.Sequential([keras.Input(shape=(image_size, image_size, 3)), layers.Rescaling(255.0), layers.Resizing(height=kid_image_size, width=kid_image_size), layers.Lambda(keras.applications.inception_v3.preprocess_input), keras.applications.InceptionV3(include_top=False, input_shape=(kid_image_size, kid_image_size, 3), weights='imagenet'), layers.GlobalAveragePooling2D()], name='inception_encoder')",152,stable-diffusion/ddim/ddim.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\ddim\ddim.py
"self.encoder(generated_images, training=False)",174,"self.encoder = keras.Sequential([keras.Input(shape=(image_size, image_size, 3)), layers.Rescaling(255.0), layers.Resizing(height=kid_image_size, width=kid_image_size), layers.Lambda(keras.applications.inception_v3.preprocess_input), keras.applications.InceptionV3(include_top=False, input_shape=(kid_image_size, kid_image_size, 3), weights='imagenet'), layers.GlobalAveragePooling2D()], name='inception_encoder')",152,stable-diffusion/ddim/ddim.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\ddim\ddim.py
"self.encoder(real_images, training=False)",154,"self.encoder = keras.Sequential([keras.Input(shape=(image_size, image_size, 3)), layers.Rescaling(255.0), layers.Resizing(height=kid_image_size, width=kid_image_size), layers.Lambda(keras.applications.inception_v3.preprocess_input), keras.applications.InceptionV3(include_top=False, input_shape=(kid_image_size, kid_image_size, 3), weights='imagenet'), layers.GlobalAveragePooling2D()], name='inception_encoder')",133,stable-diffusion/ddim/deeplesion.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\ddim\deeplesion.py
"self.encoder(generated_images, training=False)",155,"self.encoder = keras.Sequential([keras.Input(shape=(image_size, image_size, 3)), layers.Rescaling(255.0), layers.Resizing(height=kid_image_size, width=kid_image_size), layers.Lambda(keras.applications.inception_v3.preprocess_input), keras.applications.InceptionV3(include_top=False, input_shape=(kid_image_size, kid_image_size, 3), weights='imagenet'), layers.GlobalAveragePooling2D()], name='inception_encoder')",133,stable-diffusion/ddim/deeplesion.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\ddim\deeplesion.py
"self.encoder(real_images, training=False)",154,"self.encoder = keras.Sequential([keras.Input(shape=(image_size, image_size, 3)), layers.Rescaling(255.0), layers.Resizing(height=kid_image_size, width=kid_image_size), layers.Lambda(keras.applications.inception_v3.preprocess_input), keras.applications.InceptionV3(include_top=False, input_shape=(kid_image_size, kid_image_size, 3), weights='imagenet'), layers.GlobalAveragePooling2D()], name='inception_encoder')",133,stable-diffusion/semantic-synthesis/cityscapes/ddim.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\semantic-synthesis\cityscapes\ddim.py
"self.encoder(generated_images, training=False)",155,"self.encoder = keras.Sequential([keras.Input(shape=(image_size, image_size, 3)), layers.Rescaling(255.0), layers.Resizing(height=kid_image_size, width=kid_image_size), layers.Lambda(keras.applications.inception_v3.preprocess_input), keras.applications.InceptionV3(include_top=False, input_shape=(kid_image_size, kid_image_size, 3), weights='imagenet'), layers.GlobalAveragePooling2D()], name='inception_encoder')",133,stable-diffusion/semantic-synthesis/cityscapes/ddim.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\semantic-synthesis\cityscapes\ddim.py
"self.encoder(real_images, training=False)",271,"self.encoder = keras.Sequential([keras.Input(shape=(image_size, image_size, 3)), layers.Rescaling(255.0), layers.Resizing(height=kid_image_size, width=kid_image_size), layers.Lambda(keras.applications.inception_v3.preprocess_input), keras.applications.InceptionV3(include_top=False, input_shape=(kid_image_size, kid_image_size, 3), weights='imagenet'), layers.GlobalAveragePooling2D()], name='inception_encoder')",247,stable-diffusion/semantic-synthesis/highres/totalseg.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\semantic-synthesis\highres\totalseg.py
"self.encoder(generated_images, training=False)",272,"self.encoder = keras.Sequential([keras.Input(shape=(image_size, image_size, 3)), layers.Rescaling(255.0), layers.Resizing(height=kid_image_size, width=kid_image_size), layers.Lambda(keras.applications.inception_v3.preprocess_input), keras.applications.InceptionV3(include_top=False, input_shape=(kid_image_size, kid_image_size, 3), weights='imagenet'), layers.GlobalAveragePooling2D()], name='inception_encoder')",247,stable-diffusion/semantic-synthesis/highres/totalseg.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\semantic-synthesis\highres\totalseg.py
"self.encoder(real_images, training=False)",270,"self.encoder = keras.Sequential([keras.Input(shape=(image_size, image_size, 3)), layers.Rescaling(255.0), layers.Resizing(height=kid_image_size, width=kid_image_size), layers.Lambda(keras.applications.inception_v3.preprocess_input), keras.applications.InceptionV3(include_top=False, input_shape=(kid_image_size, kid_image_size, 3), weights='imagenet'), layers.GlobalAveragePooling2D()], name='inception_encoder')",246,stable-diffusion/semantic-synthesis/totalseg.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\semantic-synthesis\totalseg.py
"self.encoder(generated_images, training=False)",271,"self.encoder = keras.Sequential([keras.Input(shape=(image_size, image_size, 3)), layers.Rescaling(255.0), layers.Resizing(height=kid_image_size, width=kid_image_size), layers.Lambda(keras.applications.inception_v3.preprocess_input), keras.applications.InceptionV3(include_top=False, input_shape=(kid_image_size, kid_image_size, 3), weights='imagenet'), layers.GlobalAveragePooling2D()], name='inception_encoder')",246,stable-diffusion/semantic-synthesis/totalseg.py,pangyuteng/aigonewrong,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\pangyuteng@aigonewrong\stable-diffusion\semantic-synthesis\totalseg.py
