call_name,line_no,class_instantiation,instantiation_line_no,relative_file_path,repository_name,file_path
"model(im, augment=augment, visualize=visualize)",115,"model = DetectMultiBackend(weights, device=device, dnn=dnn)",80,detect.py,hukaixuan19970627/yolov5_obb,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\hukaixuan19970627@yolov5_obb\detect.py
"model(imgs, size=320)",141,"model = DetectMultiBackend(path, device=device)",46,hubconf.py,hukaixuan19970627/yolov5_obb,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\hukaixuan19970627@yolov5_obb\hubconf.py
"model(imgs, size=320)",141,model = AutoShape(model),59,hubconf.py,hukaixuan19970627/yolov5_obb,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\hukaixuan19970627@yolov5_obb\hubconf.py
self.conv(x),49,"self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p), groups=g, bias=False)",41,models/common.py,hukaixuan19970627/yolov5_obb,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\hukaixuan19970627@yolov5_obb\models\common.py
self.m(self.cv1(inputs)),149,"self.m = keras.Sequential([TFBottleneck(c_, c_, shortcut, g, e=1.0, w=w.m[j]) for j in range(n)])",146,models/tf.py,hukaixuan19970627/yolov5_obb,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\hukaixuan19970627@yolov5_obb\models\tf.py
self.m(self.cv1(inputs)),166,"self.m = keras.Sequential([TFBottleneck(c_, c_, shortcut, g, e=1.0, w=w.m[j]) for j in range(n)])",146,models/tf.py,hukaixuan19970627/yolov5_obb,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\hukaixuan19970627@yolov5_obb\models\tf.py
self.m(self.cv1(inputs)),166,"self.m = keras.Sequential([TFBottleneck(c_, c_, shortcut, g, e=1.0, w=w.m[j]) for j in range(n)])",163,models/tf.py,hukaixuan19970627/yolov5_obb,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\hukaixuan19970627@yolov5_obb\models\tf.py
self.m(x),194,"self.m = keras.Sequential([TFBottleneck(c_, c_, shortcut, g, e=1.0, w=w.m[j]) for j in range(n)])",146,models/tf.py,hukaixuan19970627/yolov5_obb,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\hukaixuan19970627@yolov5_obb\models\tf.py
self.m(x),194,"self.m = keras.Sequential([TFBottleneck(c_, c_, shortcut, g, e=1.0, w=w.m[j]) for j in range(n)])",163,models/tf.py,hukaixuan19970627/yolov5_obb,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\hukaixuan19970627@yolov5_obb\models\tf.py
self.m(y1),195,"self.m = keras.Sequential([TFBottleneck(c_, c_, shortcut, g, e=1.0, w=w.m[j]) for j in range(n)])",146,models/tf.py,hukaixuan19970627/yolov5_obb,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\hukaixuan19970627@yolov5_obb\models\tf.py
self.m(y1),195,"self.m = keras.Sequential([TFBottleneck(c_, c_, shortcut, g, e=1.0, w=w.m[j]) for j in range(n)])",163,models/tf.py,hukaixuan19970627/yolov5_obb,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\hukaixuan19970627@yolov5_obb\models\tf.py
self.m(y2),196,"self.m = keras.Sequential([TFBottleneck(c_, c_, shortcut, g, e=1.0, w=w.m[j]) for j in range(n)])",146,models/tf.py,hukaixuan19970627/yolov5_obb,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\hukaixuan19970627@yolov5_obb\models\tf.py
self.m(y2),196,"self.m = keras.Sequential([TFBottleneck(c_, c_, shortcut, g, e=1.0, w=w.m[j]) for j in range(n)])",163,models/tf.py,hukaixuan19970627/yolov5_obb,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\hukaixuan19970627@yolov5_obb\models\tf.py
model(imgs),325,model = torch.nn.DataParallel(model),205,train.py,hukaixuan19970627/yolov5_obb,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\hukaixuan19970627@yolov5_obb\train.py
model(im),194,"model = DetectMultiBackend(weights, device=device, dnn=dnn)",137,val.py,hukaixuan19970627/yolov5_obb,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\hukaixuan19970627@yolov5_obb\val.py
"model(im, augment=augment, val=True)",194,"model = DetectMultiBackend(weights, device=device, dnn=dnn)",137,val.py,hukaixuan19970627/yolov5_obb,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\hukaixuan19970627@yolov5_obb\val.py
