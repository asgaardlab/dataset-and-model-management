call_root_type,method_name,method_call,line_no,call_root,call_root_line_no,qualifying_name,call_root_package,relative_file_path,repository_name,file_path
import,load,"return yaml.load(open(filename, 'r'))",39,"import glob, os, yaml",8.0,yaml.load,yaml,check_n_format.py,zhengying-liu/autodl-contrib,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\zhengying-liu@autodl-contrib\check_n_format.py
import,load,self._dataset_info = yaml.load(f),797,import yaml,21.0,yaml.load,yaml,utils/dataset_manager.py,zhengying-liu/autodl-contrib,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\zhengying-liu@autodl-contrib\utils\dataset_manager.py
assignment_import,fit,"clf.fit(X_train, y_train)",177,clf = RandomForestClassifier(),176.0,sklearn.ensemble.RandomForestClassifier.fit,sklearn,utils/formatting_pipeline.py,zhengying-liu/autodl-contrib,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\zhengying-liu@autodl-contrib\utils\formatting_pipeline.py
import,load,"metadata = yaml.load(open('metadata', 'r'))",286,import yaml,44.0,yaml.load,yaml,utils/automl_format/ingestion_program/data_io.py,zhengying-liu/autodl-contrib,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\zhengying-liu@autodl-contrib\utils\automl_format\ingestion_program\data_io.py
import,load,"metadata = yaml.load(open(os.path.join(input_dir, 'metadata'), 'r'))",294,import yaml,44.0,yaml.load,yaml,utils/automl_format/ingestion_program/data_io.py,zhengying-liu/autodl-contrib,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\zhengying-liu@autodl-contrib\utils\automl_format\ingestion_program\data_io.py
import,load,return pickle.load(pickle_file),135,import pickle,23.0,pickle.load,pickle,utils/automl_format/ingestion_program/data_manager.py,zhengying-liu/autodl-contrib,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\zhengying-liu@autodl-contrib\utils\automl_format\ingestion_program\data_manager.py
import,load,return pickle.load(pickle_file),167,import pickle,23.0,pickle.load,pickle,utils/automl_format/ingestion_program/data_manager.py,zhengying-liu/autodl-contrib,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\zhengying-liu@autodl-contrib\utils\automl_format\ingestion_program\data_manager.py
assignment_import,load,M = M.load(modelname),209,M = model(),200.0,model.model.load,model,utils/automl_format/ingestion_program/ingestion.py,zhengying-liu/autodl-contrib,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\zhengying-liu@autodl-contrib\utils\automl_format\ingestion_program\ingestion.py
assignment_unknown,fit,"M.fit(D.data['X_train'], D.data['Y_train'])",217,M = M.load(modelname),209.0,M.load.fit,M,utils/automl_format/ingestion_program/ingestion.py,zhengying-liu/autodl-contrib,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\zhengying-liu@autodl-contrib\utils\automl_format\ingestion_program\ingestion.py
import,load,dataset_info = yaml.load(f),129,import yaml,17.0,yaml.load,yaml,utils/dataset_test/inspect_dataset.py,zhengying-liu/autodl-contrib,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\zhengying-liu@autodl-contrib\utils\dataset_test\inspect_dataset.py
import,load,"dict = pickle.load(fo, encoding='bytes')",26,import pickle,24.0,pickle.load,pickle,utils/image/format_cifar10.py,zhengying-liu/autodl-contrib,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\zhengying-liu@autodl-contrib\utils\image\format_cifar10.py
import,load,"dict = pickle.load(fo, encoding='bytes')",21,import pickle,19.0,pickle.load,pickle,utils/image/format_cifar100.py,zhengying-liu/autodl-contrib,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\zhengying-liu@autodl-contrib\utils\image\format_cifar100.py
import,load,return pickle.load(f),28,import pickle,16.0,pickle.load,pickle,utils/series/speech_to_tfrecords.py,zhengying-liu/autodl-contrib,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\zhengying-liu@autodl-contrib\utils\series\speech_to_tfrecords.py
import,load,info = json.load(json_file),24,import json,17.0,json.load,json,utils/text/nlp_to_tfrecords.py,zhengying-liu/autodl-contrib,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\zhengying-liu@autodl-contrib\utils\text\nlp_to_tfrecords.py
