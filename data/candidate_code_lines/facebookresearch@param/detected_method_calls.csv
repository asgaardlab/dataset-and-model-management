call_root_type,method_name,method_call,line_no,call_root,call_root_line_no,qualifying_name,call_root_package,relative_file_path,repository_name,file_path
import,load,self.comms_trace = json.load(raw_comms_trace),1192,import json,12,json.load,json,train/comms/pt/commsTraceReplay.py,facebookresearch/param,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\facebookresearch@param\train\comms\pt\commsTraceReplay.py
import,load,self.comms_trace = json.load(f),1196,import json,12,json.load,json,train/comms/pt/commsTraceReplay.py,facebookresearch/param,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\facebookresearch@param\train\comms\pt\commsTraceReplay.py
import,loads,self.comms_trace = json.loads(comms_trace_str.decode()),1223,import json,12,json.loads,json,train/comms/pt/commsTraceReplay.py,facebookresearch/param,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\facebookresearch@param\train\comms\pt\commsTraceReplay.py
import,load,"self.X = torch.load(f""{self.synthetic_data_folder}/X_0.pt"")",211,import torch,16,torch.load,torch,train/comms/pt/dlrm_data.py,facebookresearch/param,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\facebookresearch@param\train\comms\pt\dlrm_data.py
import,load,"self.lS_o = torch.load(f""{self.synthetic_data_folder}/lS_o_0.pt"")",212,import torch,16,torch.load,torch,train/comms/pt/dlrm_data.py,facebookresearch/param,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\facebookresearch@param\train\comms\pt\dlrm_data.py
import,load,"self.lS_i = torch.load(f""{self.synthetic_data_folder}/lS_i_0.pt"")",213,import torch,16,torch.load,torch,train/comms/pt/dlrm_data.py,facebookresearch/param,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\facebookresearch@param\train\comms\pt\dlrm_data.py
import,load,"self.T = torch.load(f""{self.synthetic_data_folder}/T_0.pt"")",214,import torch,16,torch.load,torch,train/comms/pt/dlrm_data.py,facebookresearch/param,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\facebookresearch@param\train\comms\pt\dlrm_data.py
import,load,self.bench_config = json.load(config_file),122,import json,2,json.load,json,train/compute/python/lib/config.py,facebookresearch/param,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\facebookresearch@param\train\compute\python\lib\config.py
import,loads,self.bench_config = json.loads(config_json),126,import json,2,json.loads,json,train/compute/python/lib/config.py,facebookresearch/param,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\facebookresearch@param\train\compute\python\lib\config.py
import,loads,"config = json.loads(bytes(shm.buf[:]).decode(""utf-8"", ""strict""))",57,import json,9,json.loads,json,train/compute/python/pytorch/run_batch.py,facebookresearch/param,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\facebookresearch@param\train\compute\python\pytorch\run_batch.py
import,load,config = json.load(config_file),61,import json,9,json.load,json,train/compute/python/pytorch/run_batch.py,facebookresearch/param,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\facebookresearch@param\train\compute\python\pytorch\run_batch.py
import,load,self.eg = ExecutionGraph(json.load(eg_trace)),217,import json,3,json.load,json,train/compute/python/tools/eg_replay.py,facebookresearch/param,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\facebookresearch@param\train\compute\python\tools\eg_replay.py
import,load,self.eg = ExecutionGraph(json.load(f)),221,import json,3,json.load,json,train/compute/python/tools/eg_replay.py,facebookresearch/param,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\facebookresearch@param\train\compute\python\tools\eg_replay.py
import,load,self.eg = ExecutionGraph(json.load(eg_trace)),248,import json,3,json.load,json,train/compute/python/tools/eg_replay.py,facebookresearch/param,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\facebookresearch@param\train\compute\python\tools\eg_replay.py
import,load,self.eg = ExecutionGraph(json.load(f)),252,import json,3,json.load,json,train/compute/python/tools/eg_replay.py,facebookresearch/param,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\facebookresearch@param\train\compute\python\tools\eg_replay.py
import,load,execution_graph: ExecutionGraph = ExecutionGraph(json.load(execution_data)),773,import json,10,json.load,json,train/compute/python/tools/execution_graph.py,facebookresearch/param,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\facebookresearch@param\train\compute\python\tools\execution_graph.py
import,load,"indices_tensor = torch.load(indices_file, map_location=target_device)",185,import torch,7,torch.load,torch,train/compute/python/workloads/pytorch/split_table_batched_embeddings_ops.py,facebookresearch/param,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\facebookresearch@param\train\compute\python\workloads\pytorch\split_table_batched_embeddings_ops.py
import,load,"offsets_tensor = torch.load(offsets_file, map_location=target_device)",186,import torch,7,torch.load,torch,train/compute/python/workloads/pytorch/split_table_batched_embeddings_ops.py,facebookresearch/param,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\facebookresearch@param\train\compute\python\workloads\pytorch\split_table_batched_embeddings_ops.py
import,load,per_sample_weights_tensor = torch.load(,189,import torch,7,torch.load,torch,train/compute/python/workloads/pytorch/split_table_batched_embeddings_ops.py,facebookresearch/param,C:\Users\tajki\OneDrive\Documents\GitHub\dataset-model-source_code-integration-analyzer\data\repositories_for_manual_analysis\facebookresearch@param\train\compute\python\workloads\pytorch\split_table_batched_embeddings_ops.py
